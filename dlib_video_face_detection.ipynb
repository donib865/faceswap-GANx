{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection for video input\n",
    "Images of detected faces will be saved to `./faces/fXroiY.png`, where `X` represents the Xth frame and `Y` the Yth face in Xth frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install requirements\n",
    "\n",
    "========== CAUTION ==========\n",
    "\n",
    "If you are running on local machine. Please read [this blog](http://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/) before pip installing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "import face_recognition\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Config &  init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_faces\n",
    "global global_faces_vel\n",
    "global frame_missingbox\n",
    "global frames\n",
    "frames = 0\n",
    "global_faces = ()\n",
    "global_faces_vel = ()\n",
    "frame_missingbox = 0\n",
    "\n",
    "# only those faces having size > image size / 50 will be saved.\n",
    "# e.g., given 800 x 600 input, the minimum face images saved will be about 98 x 98.\n",
    "min_face_scale = 1/50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crop faces\n",
    "Since dlib's cnn model performs really well on face deteciton, applying box-missing frame compensation is not needed.\n",
    "But for OpenCV's Haar-cascade Detection, compensating box-missing grame will increase the chance to crop face images in different angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_img):   \n",
    "    global global_faces\n",
    "    global frame_missingbox\n",
    "    global frames\n",
    "    frames += 1\n",
    "    # Resize input image if necessary.\n",
    "    #img = cv2.resize(input_img, (input_img.shape[1]//3,input_img.shape[0]//3))\n",
    "    img = input_img\n",
    "    faces = face_recognition.face_locations(img, model=\"cnn\")\n",
    "    size_img = img.shape[0] * img.shape[1]\n",
    "    \n",
    "    face_detected = False\n",
    "    idx = 0\n",
    "    for (x0,y1,x1,y0) in faces:\n",
    "        if np.abs((x1-x0) * (y1-y0)) > size_img * min_face_scale:\n",
    "            #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),5)\n",
    "            #roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[x0:x1, y0:y1,:]\n",
    "            fname = \"./faces/f\" + str(frames) + \"roi\" + str(idx) + \".png\"\n",
    "            plt.imsave(fname, roi_color)\n",
    "            idx += 1            \n",
    "            global_faces = (x0,y1,x1,y0)\n",
    "            frame_missingbox = 0\n",
    "            face_detected = True\n",
    "        else:\n",
    "            face_detected = False\n",
    "    \n",
    "    # box-missing frame compensation\n",
    "    #if not face_detected and frame_missingbox <= 5 and not global_faces is ():\n",
    "    #    (x0,y1,x1,y0) = global_faces\n",
    "    #    roi_color = img[x0:x1, y0:y1,:]\n",
    "    #    frame_missingbox += 1       \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `process_video` will be called at each frame, and image of that frame will be the argument of `process_video`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video _.mp4\n",
      "[MoviePy] Writing video _.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63027/63027 [24:03<00:00, 43.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: _.mp4 \n",
      "\n",
      "CPU times: user 17min 47s, sys: 4min 3s, total: 21min 50s\n",
      "Wall time: 24min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = '_.mp4'\n",
    "clip1 = VideoFileClip(\"INPUT_VIDEO.mp4\")\n",
    "clip = clip1.fl_image(process_video)#.subclip(0,10) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pack `./faces` folder into a zip file `./faces.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipf = zipfile.ZipFile('faces.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('faces/', zipf)\n",
    "zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neptune",
   "language": "",
   "name": "neptune-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
